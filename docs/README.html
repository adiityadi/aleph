<html>
  <head>
    <title>Aleph Documentation</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="docs.css" />
  </head>
  <body>
    <div id="content">
      <h1 id="a-l-e-p-h-aleph-logoimg32x32png">
        a l e p h <img id="logo" src="./img/32x32.png" alt="aleph logo" />
      </h1>
      <p>
        Aleph is a cross-platform desktop client and programming framework for
        developing and performing audio reactive visualizations. It is built on
        <a href="https://electronjs.org/">Electron</a> and uses
        <a href="https://p5js.org/">P5.js</a> for graphics and audio analysis.
        Aleph handles most of the behind-the-scenes work so you can get straight
        to writing code and getting things up on the screen and adds MIDI
        control support allowing for expressive live performances.
      </p>
      <h2 id="the-interface">The Interface:</h2>
      <p>
        When you first launch Aleph, you will see the editor window, which looks
        like this:
      </p>
      <p><img src="./img/ui.png" alt="aleph ui" /></p>
      <h4 id="display-settings">Display Settings:</h4>
      <p>
        Aleph displays your p5 sketches on a separate window with no UI elements
        (called the display window) so you can present fullscreen graphics on a
        secondary display while still being able to access the editor window.
        You can manually assign a screen resolution by entering values into the
        Width and Height inputs and create the display using the “Create
        Display” button. This is useful if you need an exact size for whatever
        reason. Alternatively, because Aleph supports dynamically resizable
        windows, you can simply click “Create Display” without providing a size,
        and manually resize (or maximize) the window as you see fit. Once you
        have created a display you can enter fullscreen mode by pressing CTRL+F.
      </p>
      <table>
        <thead>
          <tr>
            <th>Parameter</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Width</td>
            <td>Set the Display Window's width explicitly (optional)</td>
          </tr>
          <tr>
            <td>Height</td>
            <td>Set the Display Window's height explicitly (optional)</td>
          </tr>
          <tr>
            <td>Pixel Density</td>
            <td>
              Set the ratio of renderer pixels to display pixels. Values below
              1.0 will result in upscaling, values above 1.0 will result in
              supersampling. Can be changed in realtime and applies to any
              displays selected under "Display Selection".
            </td>
          </tr>
          <tr>
            <td>Anti-Aliasing</td>
            <td>
              Toggle anti-aliasing. Can be changed in realtime and applies to
              any displays selected under "Display Selection".
            </td>
          </tr>
          <tr>
            <td>Debug Mode</td>
            <td>
              Toggle additional warnings and debug information at the cost of
              performance. Targets all Display Windows.
            </td>
          </tr>
          <tr>
            <td>Create Display</td>
            <td>Create a new Display Window with the specified information.</td>
          </tr>
        </tbody>
      </table>
      <h4 id="display-selection">Display Selection:</h4>
      <p>
        This controls which display(s) a given sketch will be rendered on and
        where settings like anti-aliasing and pixel density are applied. It only
        becomes relevant when using Aleph with multiple display windows. The
        default setting is "All". In other words, when you change which sketch
        is being displayed that change will be reflected across all current
        display windows. However you can target specific windows to display
        sketches on by selecting the number corresponding to the desired window,
        then making a sketch change.
      </p>
      <p>
        You can control these options with MIDI (see
        <a href="#controlling-display-outputs-with-midi"
          >Controlling Display Outputs with MIDI</a
        >)
      </p>
      <h6
        id="_note-while-this-controls-which-windows-are-affected-by-sketch-changes-it-does-not-affect-other-midi-parameters-at-present---those-will-all-be-forwarded-to-every-display-window_"
      >
        <em
          >Note: while this controls which windows are affected by sketch
          changes, it does not affect other MIDI parameters at present - those
          will all be forwarded to every display window.</em
        >
      </h6>
      <h4 id="audio-settings">Audio Settings:</h4>
      <ul>
        <li><em>Volume</em>: Adjusts volume input sensitivity.</li>
        <li><em>Bass</em>: Adjusts low frequency input sensitivity.</li>
        <li><em>Mid</em>: Adjusts mid frequency input sensitivity.</li>
        <li><em>High</em>: Adjusts high frequency input sensitivity.</li>
        <li>
          <em>FFT Smooth</em>: Adjusts FFT smoothing. High smoothing values
          result in more gradual changes between frames.
        </li>
        <li>
          <em>Volume Smooth</em>: Adjusts volume smoothing. High smoothing
          values result in more gradual changes between frames.
        </li>
      </ul>
      <p>
        These knobs can be controlled with a mouse but it is also possible to
        control them with MIDI (see
        <a href="#controlling-audio-parameter-knobs-with-midi"
          >Controlling Audio Parameter Knobs with MIDI</a
        >).
      </p>
      <h4 id="import-assets">Import Assets:</h4>
      <p>
        Use the labeled buttons to import custom 3D models, images, fonts,
        videos, and glsl shaders to use in your sketches. Files will be imported
        to the folder <code>resources/app/aleph_modules/core/assets</code>.
      </p>
      <h4 id="available-assets">Available Assets:</h4>
      <p>
        Use the “show/hide” button to toggle visibility of all assets available
        to your local installation of Aleph. The files are displayed exactly as
        they should be correctly referenced in your code - ex. An imported 3D
        model called “myModel.obj” would be referenced as
        <code>assets.models.myModel</code>, as it is listed in the UI.
      </p>
      <h4 id="sketch-selection">Sketch Selection:</h4>
      <p>
        Aleph will automatically read the examples sketch folder (located at
        <code>resources/app/aleph_modules/core/sketches/examples</code>) and
        generate labeled buttons for each sketch. You can create additional
        folders to save sketches inside that <code>sketches</code> folder, i.e.
        <code>...sketches/my_live_set</code>. Aleph will only load sketches from
        a single folder at a time. To change the folder you're loading sketches
        from, use the "Select Sketch Folder" button.
      </p>
      <p>
        <img src="./img/select_sketch_folder.png" alt="select sketch folder" />
      </p>
      <p>
        You can toggle the active sketch by clicking the corresponding button of
        the sketch you would like to switch to. It is also possible to control
        sketch selection with MIDI (see
        <a href="#controlling-sketch-selection-with-midi"
          >Controlling Sketch Selection with MIDI</a
        >).
      </p>
      <p>
        If you are working with multiple displays, you can send sketches to
        specific displays (see
        <a href="#send-sketch-to-displays">Send Sketch to Displays</a>).
      </p>
      <h4 id="midi-device-selection">Midi Device Selection:</h4>
      <p>
        Aleph will automatically scan your computer for available MIDI devices
        and generate labeled buttons for each device. To select a device, simply
        click its button. This will enable you to use the device to send MIDI
        controls to Aleph. You can select multiple midi devices if you wish to
        use more than one.
      </p>
      <h6
        id="_note-you-must-select-a-midi-device-before-attempting-to-create-midi-mappings_"
      >
        <em
          >Note: you must select a MIDI device before attempting to create MIDI
          mappings!</em
        >
      </h6>
      <h4 id="midi-mapping">Midi Mapping:</h4>
      <h6
        id="_note-the-following-is-written-with-hardware-midi-controllers-in-mind-but-it-is-possible-to-send-midi-to-aleph-from-other-software-ex-ableton-live-however-you-will-need-to-create-a-midi-loopback-either-using-a-hardware-loopback-if-available-or-virtual-midi-loopback-software_"
      >
        <em
          >Note: The following is written with hardware MIDI controllers in
          mind, but it is possible to send MIDI to Aleph from other software,
          ex. Ableton Live. However you will need to create a MIDI loopback,
          either using a hardware loopback if available, or virtual MIDI
          loopback software.</em
        >
      </h6>
      <h5 id="controlling-audio-parameter-knobs-with-midi">
        Controlling Audio Parameter Knobs with MIDI:
      </h5>
      <p>
        You can assign MIDI controls to the audio control knobs on the UI by
        clicking the small box under a given control labeled "map". Clicking the
        button will make Aleph "listen" for any MIDI inputs, so simply turn a
        knob or move a fader on your MIDI controller to assign it to one of the
        audio control UI knobs on the editor window.
      </p>
      <p><img src="./img/knobs.png" alt="midi mapping knobs" /></p>
      <h5 id="controlling-sketch-selection-with-midi">
        Controlling Sketch Selection with MIDI:
      </h5>
      <p>
        You can assign MIDI controls to specific sketches to switch between
        sketches using a MIDI controller. To do so, click the button labeled
        "Midi Map Sketches", then click the sketch button you would like to map,
        then press a MIDI button to assign the button to the sketch.
      </p>
      <p>
        <img
          src="./img/sketchmapping.png"
          alt="midi mapping sketch selection"
        />
      </p>
      <h5 id="controlling-display-outputs-with-midi">
        Controlling Display Outputs with MIDI:
      </h5>
      <p>
        You can assign MIDI controls to the available display outputs under
        "Display Selection". To do so, click the button labeled "Midi Map", then
        click the desired display (or "All"), then press a button on your MIDI
        controller.
      </p>
      <p>
        <img src="./img/mapoutputs.png" alt="display output midi mapping" />
      </p>
      <h5 id="custom-midi-controls">Custom MIDI controls:</h5>
      <p>
        "Custom" in this case means these are controls you can reference in your
        p5 sketches and set up custom behavior for, as opposed to the MIDI
        assignments for controlling the audio knobs on the UI, sketch selection,
        or display selection, which have hard-coded behaviors.
      </p>
      <p>
        To create a MIDI mapping, first create a control entry by clicking “Add
        Control”. Next you can create an assignment by clicking the numbered box
        created below to “listen” for MIDI messages, then pressing/turning a
        MIDI control on your controller to assign that physical control to the
        corresponding entry. You can remove the most recently added mapping
        using the "Remove Control" button.
      </p>
      <p><img src="./img/midi-full.png" alt="midi mapping" /></p>
      <p>
        Once you have mapped all your controls, you can click “Lock Midi
        Assignment” to disable the assignment buttons. This prevents you from
        accidentally overwriting control entries.
      </p>
      <p>
        You can force momentary/hold behavior (as opposed to toggle) to buttons
        by enabling the "Force Momentary Mode".
      </p>
      <h6
        id="_note-if-sending-midi-control-messages-to-change-sketches-directly-from-a-daw-like-ableton-live-it-might-be-necessary-to-enable-forced-momentary-mode-due-to-the-way-certain-software-handles-midi-off-messages_"
      >
        <em
          >Note: If sending MIDI control messages to change sketches directly
          from a DAW like Ableton Live, it might be necessary to enable forced
          momentary mode due to the way certain software handles MIDI off
          messages.</em
        >
      </h6>
      <h5 id="saving-and-loading-midi-mappings">
        Saving and Loading MIDI Mappings
      </h5>
      <p>
        Once you've created a mapping file, you can save it to disk by clicking
        the "Save Midi Mapping" button. It will bring up a save dialog for you
        to name the file.
      </p>
      <p>
        To load a mapping file, click the "Load Midi Mapping" button. A dialog
        will appear for you to select the mapping file to load.
      </p>
      <h2 id="using-aleph">Using Aleph</h2>
      <h4 id="getting-audio-into-aleph">Getting Audio Into Aleph:</h4>
      <p>
        <strong
          >If you only need to receive audio on the computer running
          Aleph</strong
        >
        (i.e. the audio is being generated on another device), you simply need
        to make sure the input on your soundcard receiving the audio input is
        selected as the primary input in the OS's sound configuration settings.
        You could even use a built-in microphone to get audio into Aleph, though
        this isn't recommended in most cases.
      </p>
      <p>
        <strong
          >If you need to send and receive audio on the same computer</strong
        >, you will need to configure a loopback. There are two basic approaches
        to routing loopbacks into Aleph - physically routing a cable from the
        output of your soundcard to it's input, or using some software like
        <a href="http://jackaudio.org/">JACK</a>. My preferred approach is a
        physical loopback as there is less latency and CPU overhead compared
        with a software loopback.
      </p>
      <h4 id="adjusting-audio-parameters">Adjusting Audio Parameters</h4>
      <p>
        A common problem with audio-reactive visualizations is that every song
        has different sonic characteristics. Many songs are mastered at
        different levels, making it hard to reliably link a visual parameter to
        some threshold of volume, for example. To address this, Aleph has some
        basic audio controls that you can use to adjust the audio signal inside
        Aleph (i.e. this will have no effect on the audible sound source). You
        can adjust the overall volume, the volume of different frequency bands,
        and adjust the smoothing of both the volume and the FFT.
      </p>
      <h4 id="using-midi-to-control-sketches">
        Using MIDI To Control Sketches
      </h4>
      <p>
        One of the most powerful features that Aleph brings to the table over
        vanilla p5 is it's ability to receive MIDI control input, which you can
        use to control virtually any aspect of your sketches. You can use
        physical MIDI controllers or even send MIDI to Aleph from another
        program like Ableton Live, Max, or pd. See the "MIDI" section under
        "Writing Code" below for more detail on creating MIDI mappings.
      </p>
      <h2 id="writing-code">Writing Code</h2>
      <h4 id="a-note-on-p5">A Note on P5:</h4>
      <p>
        Writing sketches for Aleph is nearly identical to writing vanilla p5
        sketches. The primary difference is that a number of p5 related things
        are handled for you by Aleph, like audio analysis and dealing with files
        &amp; windows. So if you ever encounter issues with your sketches or are
        looking for learning resources - look to the
        <a href="https://p5js.org/community/">p5.js community</a> and their
        growing library of
        <a href="https://p5js.org/reference/">documentation</a> and
        <a href="https://p5js.org/examples/">examples</a>!
      </p>
      <h4 id="folder-structure">Folder Structure:</h4>
      <p>Aleph’s folders are structured like this:</p>
      <pre><code>├───assets
│   ├───fonts
│   ├───icons
│   │   ├───mac
│   │   ├───png
│   │   └───win
│   ├───models
│   ├───shaders
│   ├───images
|   └───videos
├───core
│   ├───css
│   ├───html
│   └───js
├───docs
├───mappings
├───scripts
└───sketches
</code></pre>
      <h4 id="creating-sketches">Creating Sketches:</h4>
      <p>
        You can add new sketches by clicking one of the create sketch buttons
        under the “Sketch Selection” header, which come in 2D and 3D flavors.
      </p>
      <p>
        Follow the save dialog and assign your sketch a name. This will create a
        copy of the Aleph p5 module template which looks like this:
      </p>
      <h5 id="2d-template">2D Template</h5>
      <pre><code class="javascript language-javascript">function setup() {
  // code you only want to run ONCE
}

function draw() {
  // code you want to run every frame
}

exports.run = () =&gt; {
  utils.render2D(state[path.basename(__filename)], setup, draw);
};
</code></pre>
      <p>or this, if you're using the 3D option:</p>
      <h5 id="3d-template">3D Template</h5>
      <pre><code class="javascript language-javascript">function setup() {
  // code you only want to run ONCE
}

function draw() {
  // code you want to run every frame
}

exports.run = () =&gt; {
  utils.render3D(state[path.basename(__filename)], setup, _3D, draw, "reset");
};
</code></pre>
      <p>
        The final argument to the <code>utils.renderLoop</code> function
        (<code>"reset"</code>) is an optional flag that will reset transforms
        and lighting information every frame. Rule of thumb: if you want a
        constant tranform, like rotating an object X degrees every frame, you
        want to reset transforms, otherwise the rotation will stack across
        frames. If you want to apply some non-constant rotation (maybe your
        rotation is based on audio input), you probably don't want to reset
        transforms. To remove this <code>reset</code> behavior, simply remove
        the <code>"reset"</code> string. See the <code>3D.js</code> (<code
          >reset</code
        >
        disabled) vs <code>3Dmodel.js</code> (<code>reset</code> enabled)
        example sketches for real examples of this.
      </p>
      <h6
        id="_note-that-the-setup-and-draw-functions-above-are-not-actually-native-p5-functions-though-they-behave-similarly-setup-will-execute-whatever-code-is-inside-of-it-one-time-while-any-code-placed-in-the-draw-function-will-run-once-per-frame-as-long-as-the-sketch-is-running_"
      >
        <em
          >Note that the <code>setup()</code> and <code>draw()</code> functions
          above are not actually native p5 functions, though they behave
          similarly. <code>setup()</code> will execute whatever code is inside
          of it one time, while any code placed in the
          <code>draw()</code> function will run once per frame as long as the
          sketch is running.</em
        >
      </h6>
      <p>
        <strong
          >In the majority of cases, you will never need to touch the code
          inside the <code>exports.run</code> function of each Aleph sketch,
          especially for 2D sketches.</strong
        >
      </p>
      <h4 id="mixed-2d3d-rendering">Mixed 2D/3D Rendering:</h4>
      <p>
        Aleph uses p5's default 2D renderer as it's primary renderer to display
        the final image, but it creates spare 2D and 3D graphics buffers
        (renderers), allowing you to draw into offscreen buffers which
        ultimately get drawn back into the main 2D renderer. This enables you to
        combine 2D and 3D graphics within a single sketch.
      </p>
      <p>
        The reason Aleph's primary renderer is not 3D is that p5's 2D renderer
        has functionality that (at present) has not been implemented in their 3D
        (webgl based) renderer. This way you get the best of both worlds - want
        to draw stuff in 3D but then apply p5's <code>copy()</code> function
        (for example), which only works in 2D? You can do that. Aleph also
        generates a spare offscreen 2D buffer for if you want to do things like
        paint an entire 2D canvas across a 3D model as a texture, for example.
        This spare 2D renderer is accessed by calling <code>_2D.</code> before
        any standard p5 function like <code>_2D.line()</code>,
        <code>_2D.fill()</code>, <code>_2D.background()</code>, etc. The 3D
        renderer is accessed in the same way, but with <code>_3D.</code> before
        p5 functions. Check out the <code>mixed2D_3D.js</code> example sketch to
        see some of this in action. If the concept of offscreen buffers is
        making you scratch your head,
        <a href="https://p5js.org/examples/structure-create-graphics.html"
          >check this example out</a
        >.
      </p>
      <h3 id="built-in-objects">Built-in Objects:</h3>
      <h4 id="audio">Audio:</h4>
      <p>
        Aleph’s built-in <code>audio</code> object contains the following
        read-only properties:
      </p>
      <table>
        <thead>
          <tr>
            <th>Property</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>volume</td>
            <td>
              returns a value between 0.0 and 1.0 representing the current
              amplitude of the input signal.
            </td>
          </tr>
          <tr>
            <td>bass</td>
            <td>
              returns a value between 0.0 and 255 representing the amount of
              energy between 20-150Hz.
            </td>
          </tr>
          <tr>
            <td>mid</td>
            <td>
              returns a value between 0.0 and 255 representing the amount of
              energy between 400-2600Hz.
            </td>
          </tr>
          <tr>
            <td>high</td>
            <td>
              returns a value between 0.0 and 255 representing the amount of
              energy between 5200-14000Hz.
            </td>
          </tr>
          <tr>
            <td>leftVol</td>
            <td>
              returns a value between 0.0 and 1.0 representing the amplitude of
              the left audio channel.
            </td>
          </tr>
          <tr>
            <td>rightVol</td>
            <td>
              returns a value between 0.0 and 1.0 representing the amplitude of
              the left audio channel.
            </td>
          </tr>
          <tr>
            <td>volEased</td>
            <td>
              returns a smoothed value between 0.0 and 1.0 representing the
              amplitude of the master audio channel. Adjust the smoothing factor
              using the “vol. smooth” knob on the GUI.
            </td>
          </tr>
          <tr>
            <td>leftVolEased</td>
            <td>
              returns a smoothed value between 0.0 and 1.0 representing the
              amplitude of the left audio channel. Adjust the smoothing factor
              using the “vol. smooth” knob on the GUI.
            </td>
          </tr>
          <tr>
            <td>rightVolEased</td>
            <td>
              returns a smoothed value between 0.0 and 1.0 representing the
              amplitude of the right audio channel. Adjust the smoothing factor
              using the “vol. smooth” knob on the GUI.
            </td>
          </tr>
          <tr>
            <td>fft</td>
            <td>
              FFT analyzes a very short snapshot of sound called a sample
              buffer. It returns an array of amplitude measurements, referred to
              as bins. The array is 1024 bins long by default. You can change
              the bin array length, but it must be a power of 2 between 16 and
              1024 in order for the FFT algorithm to function correctly. The
              actual size of the FFT buffer is twice the number of bins, so
              given a standard sample rate, the buffer is 2048/44100 seconds
              long.
            </td>
          </tr>
          <tr>
            <td>spectrum</td>
            <td>
              returns an array of amplitude values (between 0 and 255) across
              the frequency spectrum. Length is equal to FFT bins (1024 by
              default). The array indices correspond to frequencies (i.e.
              pitches), from the lowest to the highest that humans can hear.
              Each value represents amplitude at that slice of the frequency
              spectrum.
            </td>
          </tr>
          <tr>
            <td>waveform</td>
            <td>
              returns an array of amplitude measurements (between -1 and +1)
              that represent a snapshot of amplitude readings in a single
              buffer. Length will be equal to bins (defaults to 1024). Can be
              used to draw the waveform of a sound.
            </td>
          </tr>
          <tr>
            <td>spectralCentroid</td>
            <td>
              returns the spectral centroid of the input signal. The spectral
              centroid indicates where the "center of mass" of the spectrum is
              located. Perceptually, it has a connection with the impression of
              "brightness" of a sound.
            </td>
          </tr>
        </tbody>
      </table>
      <h4 id="assets">Assets:</h4>
      <p>
        Aleph generates an object called <code>assets</code> by scanning your
        local assets folder. This object contains:
      </p>
      <ul>
        <li>
          <p>
            <em>models</em>: 3D models you can import, manipulate, and display
            in your sketches. Currently p5 only supports models in the .obj
            format.
          </p>
        </li>
        <li>
          <p>
            <em>images</em>: import gif, jpg, or png files. you can use them as
            textures to wrap 3D geometry or with any of p5's image related
            functions like <code>image()</code> or <code>loadPixels()</code>.
          </p>
        </li>
        <li>
          <p>
            <em>fonts</em>: load custom .otf or .ttf fonts to use in your
            sketches.
          </p>
        </li>
        <li>
          <p>
            <em>shaders</em>: load custom glsl shaders to use in your sketches.
            shaders are massively performant compared with native p5 rendering,
            so consider looking into glsl for more complex shading, particle
            systems, etc.
          </p>
        </li>
        <li>
          <p>
            <em>videos</em>: load videos to use in your sketches. videos can be
            played back directly, altered, or used as textures to wrap 3D
            meshes. note that ideally videos used as textures should have a
            power-of-two resolution (256, 512, 1024, etc). video formats that
            work in chromium should work in Aleph.
          </p>
        </li>
      </ul>
      <p>
        You can access them in your p5 sketches like this:
        <code>assets.models.nameOfModel</code> where "nameOfModel" is the
        filename stripped of its extension. Ex. to access an imported 3D model
        called “car.obj”, you would use <code>assets.models.car</code>. This
        same naming convention applies to all asset types. To see how to
        reference assets in your sketc, you can expand the
        <a href="#available-assets">Available Assets</a> dropdown.
      </p>
      <p>
        Items in the <code>assets</code> object also come with a reference to
        their file path on disk if you should need it for any reason - ex.
        <code>assets.images.babel.path</code>.
      </p>
      <h4 id="rendering-images-videos-and-animated-gifs">
        Rendering Images, Videos, and Animated Gifs
      </h4>
      <p>
        To display images, use the <code>image()</code> function, passing in a
        reference to an image <code>asset</code>:
      </p>
      <pre><code class="javascript language-javascript">image(assets.images.NAME_OF_IMAGE, X_POSITION, Y_POSITION, WIDTH, HEIGHT);
</code></pre>
      <p>
        To display videos, you do the same, but pass in a video reference
        instead:
      </p>
      <pre><code class="javascript language-javascript">image(assets.videos.NAME_OF_VIDEO, X_POSITION, Y_POSITION, WIDTH, HEIGHT);
</code></pre>
      <p>
        <em
          >Note: when working with videos, setting a
          <code>background()</code> has been known to introduce flickering when
          working with high resolution videos.</em
        >
      </p>
      <p>
        For both images and videos, it's possible to load all the pixels and
        manipulate them directly using
        <a href="https://p5js.org/reference/#/p5/loadPixels"
          ><code>loadPixels()</code></a
        >
        and
        <a href="https://p5js.org/reference/#/p5/updatePixels"
          ><code>updatePixels()</code></a
        >.
      </p>
      <p>
        You can pass a gif file to <code>image()</code>, but it will only render
        the first frame. To render an <em>animated</em> gif, use the built-in
        <code>utils.renderGif()</code> utility. However here instead of passing
        an image, simply pass the <em>path</em> to the image.
      </p>
      <pre><code class="javascript language-javascript">utils.renderGif(assets.images.NAME_OF_GIF.path);
</code></pre>
      <p>
        If used as above, with only a path given, it will display the gif in the
        center of the screen at it's native size. However you can pass in an
        options object with a number of fields that allow you to customize how
        the gif is rendered:
      </p>
      <pre><code class="javascript language-javascript">utils.renderGif(pathToGif, {
  x: mouseX,
  y: mouseY,
  scale: map(mouseY, 0, height, 0.5, 2),
  filters: [
    {
      name: "invert",
      amount: map(mouseX, 0, width, 0, 1),
    },
    {
      name: "blur",
      amount: "3px",
    },
  ],
});
</code></pre>
      <p>
        <code>x</code> and <code>y</code> take in pixel coordinates (relative to
        the center of the gif) to describe its placement.
      </p>
      <p>
        <code>scale</code> takes a number representing the scale multiplier -
        i.e. <code>2</code> = <code>200%</code> scale.
      </p>
      <p>
        <code>filters</code> takes an array of objects representing
        <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/filter"
          >standard CSS filters</a
        >.
      </p>
      <h4 id="midi">Midi:</h4>
      <p>
        Through the MIDI mapping process, Aleph will generate an array called
        <code>midi</code> which contains objects representing each assigned MIDI
        control, each with the index, note, CC value, and the name of the
        physical controller the MIDI control belongs to. “Index” in this case
        refers to the number on the button (in Aleph’s interface) that
        corresponds with a given control.
      </p>
      <p>
        <img src="./img/midi.png" alt="midi indexes" /> <br />
        Here we have 8 MIDI entries with indexes 0-7
      </p>
      <p>
        You can access MIDI values in your p5 sketches like this:
        <code>midi[x].value</code> where <code>x</code> is the index of the
        control. Note that all MIDI controls output values between 0-127, so you
        might have to remap the values to different ranges depending on what
        you’re trying to accomplish. This can be accomplished easily using p5’s
        <code>map()</code> function.
      </p>
      <h4 id="debugging">Debugging:</h4>
      <p>
        Aleph includes Chromium devtools which you can use to log things out to
        the console, capture performance statistics, and more. You can access
        the DevTools by pressing F12 on any platform, or the following OS
        specific hotkeys:
      </p>
      <p>
        <strong>Windows/Linux</strong>: CTRL + SHIFT + I <br />
        <strong>MacOS</strong>: CMD + ALT + I
      </p>
      <h6
        id="_note-each-aleph-window-contains-its-own-separate-instance-of-devtools-including-the-ui-window-if-you-wish-to-debug-your-p5-sketches-open-devtools-on-the-window-displaying-your-sketches_"
      >
        <em
          >Note: each Aleph window contains its own separate instance of
          DevTools (including the UI window). If you wish to debug your p5
          sketches, open DevTools on the window displaying your sketches.</em
        >
      </h6>
      <h2 id="resources">Resources:</h2>
      <p>
        <a href="https://github.com/agohorel/aleph">Aleph Github</a> <br />
        <a href="https://p5js.org/reference/">P5 docs</a> <br />
        <a href="https://electronjs.org/docs">Electron docs</a> <br />
        <a href="https://nodejs.org/en/docs/">Node.js docs</a> <br />
        <a href="https://www.chromium.org/developers">Chromium docs</a>
      </p>
      <h2 id="submitting-feedback">Submitting Feedback</h2>
      <p>
        Please submit bugs to the
        <a href="https://github.com/agohorel/aleph/issues"
          >Aleph Github issue tracker</a
        >.<br />
        You can also submit bug reports, feature requests, and/or general
        feedback to the
        <a href="https://discordapp.com/invite/c8fUQUb">Aleph Discord server</a
        >. Good
        <a
          href="https://developer.mozilla.org/en-US/docs/Mozilla/QA/Bug_writing_guidelines"
          >bug reporting etiquette</a
        >
        is greatly appreciated!
      </p>
    </div>
  </body>
</html>
